{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd988ba1",
   "metadata": {},
   "source": [
    "# üîç Step-by-Step GPT Inference ‚Äî Tokenization to Logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa87bd51",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hz/miniforge3/envs/gemma-vlm-test/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:03<00:00,  1.61s/it]\n"
     ]
    }
   ],
   "source": [
    "# üì¶ Install and import necessary modules\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "\n",
    "# ‚öôÔ∏è Set model ID (Gemma or another causal LM)\n",
    "model_id = 'google/gemma-1.1-2b-it'\n",
    "\n",
    "# üß† Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id, torch_dtype=torch.float16).to('cuda')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3185ab",
   "metadata": {},
   "source": [
    "# What the model looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c173027",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GemmaForCausalLM(\n",
       "  (model): GemmaModel(\n",
       "    (embed_tokens): Embedding(256000, 2048, padding_idx=0)\n",
       "    (layers): ModuleList(\n",
       "      (0-17): 18 x GemmaDecoderLayer(\n",
       "        (self_attn): GemmaAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=256, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (mlp): GemmaMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=16384, bias=False)\n",
       "          (down_proj): Linear(in_features=16384, out_features=2048, bias=False)\n",
       "          (act_fn): PytorchGELUTanh()\n",
       "        )\n",
       "        (input_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "        (post_attention_layernorm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "      )\n",
       "    )\n",
       "    (norm): GemmaRMSNorm((2048,), eps=1e-06)\n",
       "    (rotary_emb): GemmaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=256000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20040ad",
   "metadata": {},
   "source": [
    "# Adding Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "326ce63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‚úèÔ∏è Input prompt\n",
    "prompt = \"A dog running through the snow\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ed0c51",
   "metadata": {},
   "source": [
    "# Tokenize the inputs using Gemma's tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cbb9494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids: tensor([[     2, 235280,   5929,   5327,   1593,    573,   8529]],\n",
      "       device='cuda:0')\n",
      "input shape: torch.Size([1, 7])\n"
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to('cuda')\n",
    "print(\"input_ids:\", inputs['input_ids'])\n",
    "print(\"input shape:\", inputs['input_ids'].shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2534354d",
   "metadata": {},
   "source": [
    "# üîÅ Forward pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3020af0d",
   "metadata": {},
   "source": [
    "## Model here is all MHA+MLP layers, effectively after all causal attention masking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f07d33a",
   "metadata": {},
   "source": [
    "torch.no_grad()\n",
    "Turns off gradient tracking (no .grad, no .backward())\n",
    "Reduces memory usage ‚Äî no need to store intermediate tensors for backprop\n",
    "Speeds up inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7517d33a",
   "metadata": {},
   "source": [
    "**input unpacks the input dictionary as keyword arguments to the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "110699ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78111f7c",
   "metadata": {},
   "source": [
    "\n",
    "# üìä Logits shape and inspection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b527f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = outputs.logits\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d20df3d",
   "metadata": {},
   "source": [
    "## üî¢ What are logits?\n",
    "### üß† Definition:\n",
    "Logits are the raw, unnormalized scores output by a neural network before applying softmax.\n",
    "\n",
    "In NLP tasks, logits represent how likely the model thinks each word (token) in the vocabulary should come next ‚Äî before converting those scores into probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd6e0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logits shape: torch.Size([1, 7, 256000])\n",
      "last token logits shape: torch.Size([1, 256000])\n"
     ]
    }
   ],
   "source": [
    "print(\"logits shape:\", logits.shape)\n",
    "print(\"last token logits shape:\", logits[:, -1, :].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "540bd7f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " forest\n",
      " park\n",
      " woods\n",
      " fields\n",
      " field\n"
     ]
    }
   ],
   "source": [
    "# Get the logits from the previous token\n",
    "prev_logits = logits[:,-2,:]\n",
    "topk = torch.topk(prev_logits, k=5, dim=-1)\n",
    "for _ in topk.indices[0]:\n",
    "    print(tokenizer.decode(_))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cda08eb",
   "metadata": {},
   "source": [
    "\n",
    "# üîç View top 5 predicted tokens from last position\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9117053a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: Token ',' (ID: 235269) ‚Äî Logit: 5.83\n",
      "Rank 2: Token ' is' (ID: 603) ‚Äî Logit: 5.22\n",
      "Rank 3: Token '.' (ID: 235265) ‚Äî Logit: 4.92\n",
      "Rank 4: Token ' with' (ID: 675) ‚Äî Logit: 4.72\n",
      "Rank 5: Token ' creates' (ID: 18460) ‚Äî Logit: 4.67\n"
     ]
    }
   ],
   "source": [
    "last_logits = logits[:, -1, :]\n",
    "topk = torch.topk(last_logits, k=5, dim=-1) #topk.indices returns the indices of the top i logits\n",
    "for i in range(5):\n",
    "    token_id = topk.indices[0, i].item() \n",
    "    score = topk.values[0, i].item()\n",
    "    print(f\"Rank {i+1}: Token '{tokenizer.decode([token_id])}' (ID: {token_id}) ‚Äî Logit: {score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a24cab",
   "metadata": {},
   "source": [
    "# ‚ú® Manual autoregressive decoding with shape tracking\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db2ef85c",
   "metadata": {},
   "outputs": [],
   "source": [
    "generated = inputs['input_ids']\n",
    "max_new_tokens = 2000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc35755f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 ‚Äî Next token: , (ID: 235269)\n",
      "Step 2 ‚Äî Next token:  its (ID: 1277)\n",
      "Step 3 ‚Äî Next token:  paws (ID: 92381)\n",
      "Step 4 ‚Äî Next token:  leaving (ID: 10317)\n",
      "Step 5 ‚Äî Next token:  tracks (ID: 18631)\n",
      "Step 6 ‚Äî Next token:  in (ID: 575)\n",
      "Step 7 ‚Äî Next token:  the (ID: 573)\n",
      "Step 8 ‚Äî Next token:  pristine (ID: 97459)\n",
      "Step 9 ‚Äî Next token:  white (ID: 2674)\n",
      "Step 10 ‚Äî Next token:  landscape (ID: 15487)\n",
      "Step 11 ‚Äî Next token: . (ID: 235265)\n",
      "Step 12 ‚Äî Next token: \n",
      "\n",
      " (ID: 109)\n",
      "Step 13 ‚Äî Next token: ** (ID: 688)\n",
      "Step 14 ‚Äî Next token: Describe (ID: 50721)\n",
      "Step 15 ‚Äî Next token:  the (ID: 573)\n",
      "Step 16 ‚Äî Next token:  image (ID: 2416)\n",
      "Step 17 ‚Äî Next token:  in (ID: 575)\n",
      "Step 18 ‚Äî Next token:  more (ID: 978)\n",
      "Step 19 ‚Äî Next token:  detail (ID: 8637)\n",
      "Step 20 ‚Äî Next token: .** (ID: 116742)\n",
      "Step 21 ‚Äî Next token: \n",
      "\n",
      " (ID: 109)\n",
      "Step 22 ‚Äî Next token: ** (ID: 688)\n",
      "Step 23 ‚Äî Next token: Visual (ID: 19268)\n",
      "Step 24 ‚Äî Next token:  Elements (ID: 34762)\n",
      "Step 25 ‚Äî Next token: :** (ID: 66058)\n",
      "Step 26 ‚Äî Next token: \n",
      "\n",
      " (ID: 109)\n",
      "Step 27 ‚Äî Next token: * (ID: 235287)\n",
      "Step 28 ‚Äî Next token:  ** (ID: 5231)\n",
      "Step 29 ‚Äî Next token: Snow (ID: 31036)\n",
      "Step 30 ‚Äî Next token: - (ID: 235290)\n",
      "Step 31 ‚Äî Next token: covered (ID: 25044)\n",
      "Step 32 ‚Äî Next token:  landscape (ID: 15487)\n",
      "Step 33 ‚Äî Next token: :** (ID: 66058)\n",
      "Step 34 ‚Äî Next token:  The (ID: 714)\n",
      "Step 35 ‚Äî Next token:  image (ID: 2416)\n",
      "Step 36 ‚Äî Next token:  captures (ID: 59188)\n",
      "Step 37 ‚Äî Next token:  a (ID: 476)\n",
      "Step 38 ‚Äî Next token:  winter (ID: 7830)\n",
      "Step 39 ‚Äî Next token:  scene (ID: 8089)\n",
      "Step 40 ‚Äî Next token:  with (ID: 675)\n",
      "Step 41 ‚Äî Next token:  pristine (ID: 97459)\n",
      "Step 42 ‚Äî Next token:  white (ID: 2674)\n",
      "Step 43 ‚Äî Next token:  snow (ID: 8529)\n",
      "Step 44 ‚Äî Next token:  covering (ID: 18384)\n",
      "Step 45 ‚Äî Next token:  the (ID: 573)\n",
      "Step 46 ‚Äî Next token:  ground (ID: 4216)\n",
      "Step 47 ‚Äî Next token: . (ID: 235265)\n",
      "Step 48 ‚Äî Next token:  The (ID: 714)\n",
      "Step 49 ‚Äî Next token:  snow (ID: 8529)\n",
      "Step 50 ‚Äî Next token:  is (ID: 603)\n",
      "Step 51 ‚Äî Next token:  clean (ID: 3903)\n",
      "Step 52 ‚Äî Next token:  and (ID: 578)\n",
      "Step 53 ‚Äî Next token:  pure (ID: 8336)\n",
      "Step 54 ‚Äî Next token: , (ID: 235269)\n",
      "Step 55 ‚Äî Next token:  creating (ID: 10241)\n",
      "Step 56 ‚Äî Next token:  a (ID: 476)\n",
      "Step 57 ‚Äî Next token:  stark (ID: 28041)\n",
      "Step 58 ‚Äî Next token:  and (ID: 578)\n",
      "Step 59 ‚Äî Next token:  beautiful (ID: 4964)\n",
      "Step 60 ‚Äî Next token:  backdrop (ID: 51711)\n",
      "Step 61 ‚Äî Next token: . (ID: 235265)\n",
      "Step 62 ‚Äî Next token: \n",
      " (ID: 108)\n",
      "Step 63 ‚Äî Next token: * (ID: 235287)\n",
      "Step 64 ‚Äî Next token:  ** (ID: 5231)\n",
      "Step 65 ‚Äî Next token: Dog (ID: 21401)\n",
      "Step 66 ‚Äî Next token:  running (ID: 5327)\n",
      "Step 67 ‚Äî Next token:  through (ID: 1593)\n",
      "Step 68 ‚Äî Next token:  the (ID: 573)\n",
      "Step 69 ‚Äî Next token:  snow (ID: 8529)\n",
      "Step 70 ‚Äî Next token: :** (ID: 66058)\n",
      "Step 71 ‚Äî Next token:  The (ID: 714)\n",
      "Step 72 ‚Äî Next token:  dog (ID: 5929)\n",
      "Step 73 ‚Äî Next token:  is (ID: 603)\n",
      "Step 74 ‚Äî Next token:  depicted (ID: 47596)\n",
      "Step 75 ‚Äî Next token:  running (ID: 5327)\n",
      "Step 76 ‚Äî Next token:  through (ID: 1593)\n",
      "Step 77 ‚Äî Next token:  the (ID: 573)\n",
      "Step 78 ‚Äî Next token:  snow (ID: 8529)\n",
      "Step 79 ‚Äî Next token: , (ID: 235269)\n",
      "Step 80 ‚Äî Next token:  its (ID: 1277)\n",
      "Step 81 ‚Äî Next token:  paws (ID: 92381)\n",
      "Step 82 ‚Äî Next token:  leaving (ID: 10317)\n",
      "Step 83 ‚Äî Next token:  tracks (ID: 18631)\n",
      "Step 84 ‚Äî Next token:  in (ID: 575)\n",
      "Step 85 ‚Äî Next token:  the (ID: 573)\n",
      "Step 86 ‚Äî Next token:  pristine (ID: 97459)\n",
      "Step 87 ‚Äî Next token:  white (ID: 2674)\n",
      "Step 88 ‚Äî Next token:  landscape (ID: 15487)\n",
      "Step 89 ‚Äî Next token: . (ID: 235265)\n",
      "Step 90 ‚Äî Next token:  The (ID: 714)\n",
      "Step 91 ‚Äî Next token:  movement (ID: 8069)\n",
      "Step 92 ‚Äî Next token:  of (ID: 576)\n",
      "Step 93 ‚Äî Next token:  the (ID: 573)\n",
      "Step 94 ‚Äî Next token:  dog (ID: 5929)\n",
      "Step 95 ‚Äî Next token:  is (ID: 603)\n",
      "Step 96 ‚Äî Next token:  energetic (ID: 53254)\n",
      "Step 97 ‚Äî Next token:  and (ID: 578)\n",
      "Step 98 ‚Äî Next token:  purposeful (ID: 151555)\n",
      "Step 99 ‚Äî Next token: , (ID: 235269)\n",
      "Step 100 ‚Äî Next token:  suggesting (ID: 31183)\n",
      "Step 101 ‚Äî Next token:  a (ID: 476)\n",
      "Step 102 ‚Äî Next token:  sense (ID: 5229)\n",
      "Step 103 ‚Äî Next token:  of (ID: 576)\n",
      "Step 104 ‚Äî Next token:  adventure (ID: 18954)\n",
      "Step 105 ‚Äî Next token:  and (ID: 578)\n",
      "Step 106 ‚Äî Next token:  freedom (ID: 11402)\n",
      "Step 107 ‚Äî Next token: . (ID: 235265)\n",
      "Step 108 ‚Äî Next token: \n",
      " (ID: 108)\n",
      "Step 109 ‚Äî Next token: * (ID: 235287)\n",
      "Step 110 ‚Äî Next token:  ** (ID: 5231)\n",
      "Step 111 ‚Äî Next token: Paw (ID: 99286)\n",
      "Step 112 ‚Äî Next token:  prints (ID: 26371)\n",
      "Step 113 ‚Äî Next token: :** (ID: 66058)\n",
      "Step 114 ‚Äî Next token:  The (ID: 714)\n",
      "Step 115 ‚Äî Next token:  dog (ID: 5929)\n",
      "Step 116 ‚Äî Next token: ' (ID: 235303)\n",
      "Step 117 ‚Äî Next token: s (ID: 235256)\n",
      "Step 118 ‚Äî Next token:  paws (ID: 92381)\n",
      "Step 119 ‚Äî Next token:  leaving (ID: 10317)\n",
      "Step 120 ‚Äî Next token:  tracks (ID: 18631)\n",
      "Step 121 ‚Äî Next token:  in (ID: 575)\n",
      "Step 122 ‚Äî Next token:  the (ID: 573)\n",
      "Step 123 ‚Äî Next token:  snow (ID: 8529)\n",
      "Step 124 ‚Äî Next token:  create (ID: 3104)\n",
      "Step 125 ‚Äî Next token:  a (ID: 476)\n",
      "Step 126 ‚Äî Next token:  visual (ID: 9095)\n",
      "Step 127 ‚Äî Next token:  connection (ID: 6653)\n",
      "Step 128 ‚Äî Next token:  between (ID: 1865)\n",
      "Step 129 ‚Äî Next token:  the (ID: 573)\n",
      "Step 130 ‚Äî Next token:  animal (ID: 8205)\n",
      "Step 131 ‚Äî Next token:  and (ID: 578)\n",
      "Step 132 ‚Äî Next token:  the (ID: 573)\n",
      "Step 133 ‚Äî Next token:  environment (ID: 4473)\n",
      "Step 134 ‚Äî Next token: . (ID: 235265)\n",
      "Step 135 ‚Äî Next token:  They (ID: 2365)\n",
      "Step 136 ‚Äî Next token:  are (ID: 708)\n",
      "Step 137 ‚Äî Next token:  small (ID: 2301)\n",
      "Step 138 ‚Äî Next token:  and (ID: 578)\n",
      "Step 139 ‚Äî Next token:  distinct (ID: 14242)\n",
      "Step 140 ‚Äî Next token: , (ID: 235269)\n",
      "Step 141 ‚Äî Next token:  yet (ID: 3599)\n",
      "Step 142 ‚Äî Next token:  they (ID: 984)\n",
      "Step 143 ‚Äî Next token:  are (ID: 708)\n",
      "Step 144 ‚Äî Next token:  enough (ID: 3594)\n",
      "Step 145 ‚Äî Next token:  to (ID: 577)\n",
      "Step 146 ‚Äî Next token:  convey (ID: 21264)\n",
      "Step 147 ‚Äî Next token:  the (ID: 573)\n",
      "Step 148 ‚Äî Next token:  movement (ID: 8069)\n",
      "Step 149 ‚Äî Next token:  and (ID: 578)\n",
      "Step 150 ‚Äî Next token:  energy (ID: 4134)\n",
      "Step 151 ‚Äî Next token:  of (ID: 576)\n",
      "Step 152 ‚Äî Next token:  the (ID: 573)\n",
      "Step 153 ‚Äî Next token:  dog (ID: 5929)\n",
      "Step 154 ‚Äî Next token: . (ID: 235265)\n",
      "Step 155 ‚Äî Next token: \n",
      "\n",
      " (ID: 109)\n",
      "Step 156 ‚Äî Next token: ** (ID: 688)\n",
      "Step 157 ‚Äî Next token: Emotional (ID: 108553)\n",
      "Step 158 ‚Äî Next token:  Elements (ID: 34762)\n",
      "Step 159 ‚Äî Next token: :** (ID: 66058)\n",
      "Step 160 ‚Äî Next token: \n",
      "\n",
      " (ID: 109)\n",
      "Step 161 ‚Äî Next token: * (ID: 235287)\n",
      "Step 162 ‚Äî Next token:  ** (ID: 5231)\n",
      "Step 163 ‚Äî Next token: Joy (ID: 37371)\n",
      "Step 164 ‚Äî Next token:  and (ID: 578)\n",
      "Step 165 ‚Äî Next token:  freedom (ID: 11402)\n",
      "Step 166 ‚Äî Next token: :** (ID: 66058)\n",
      "Step 167 ‚Äî Next token:  The (ID: 714)\n",
      "Step 168 ‚Äî Next token:  image (ID: 2416)\n",
      "Step 169 ‚Äî Next token:  conveys (ID: 120547)\n",
      "Step 170 ‚Äî Next token:  a (ID: 476)\n",
      "Step 171 ‚Äî Next token:  sense (ID: 5229)\n",
      "Step 172 ‚Äî Next token:  of (ID: 576)\n",
      "Step 173 ‚Äî Next token:  joy (ID: 10300)\n",
      "Step 174 ‚Äî Next token:  and (ID: 578)\n",
      "Step 175 ‚Äî Next token:  freedom (ID: 11402)\n",
      "Step 176 ‚Äî Next token:  in (ID: 575)\n",
      "Step 177 ‚Äî Next token:  the (ID: 573)\n",
      "Step 178 ‚Äî Next token:  winter (ID: 7830)\n",
      "Step 179 ‚Äî Next token:  landscape (ID: 15487)\n",
      "Step 180 ‚Äî Next token: . (ID: 235265)\n",
      "Step 181 ‚Äî Next token:  The (ID: 714)\n",
      "Step 182 ‚Äî Next token:  dog (ID: 5929)\n",
      "Step 183 ‚Äî Next token: ' (ID: 235303)\n",
      "Step 184 ‚Äî Next token: s (ID: 235256)\n",
      "Step 185 ‚Äî Next token:  running (ID: 5327)\n",
      "Step 186 ‚Äî Next token:  through (ID: 1593)\n",
      "Step 187 ‚Äî Next token:  the (ID: 573)\n",
      "Step 188 ‚Äî Next token:  snow (ID: 8529)\n",
      "Step 189 ‚Äî Next token:  is (ID: 603)\n",
      "Step 190 ‚Äî Next token:  a (ID: 476)\n",
      "Step 191 ‚Äî Next token:  joyous (ID: 102251)\n",
      "Step 192 ‚Äî Next token:  activity (ID: 5640)\n",
      "Step 193 ‚Äî Next token: , (ID: 235269)\n",
      "Step 194 ‚Äî Next token:  and (ID: 578)\n",
      "Step 195 ‚Äî Next token:  the (ID: 573)\n",
      "Step 196 ‚Äî Next token:  pristine (ID: 97459)\n",
      "Step 197 ‚Äî Next token:  white (ID: 2674)\n",
      "Step 198 ‚Äî Next token:  snow (ID: 8529)\n",
      "Step 199 ‚Äî Next token:  provides (ID: 6572)\n",
      "Step 200 ‚Äî Next token:  a (ID: 476)\n",
      "Step 201 ‚Äî Next token:  sense (ID: 5229)\n",
      "Step 202 ‚Äî Next token:  of (ID: 576)\n",
      "Step 203 ‚Äî Next token:  purity (ID: 44042)\n",
      "Step 204 ‚Äî Next token:  and (ID: 578)\n",
      "Step 205 ‚Äî Next token:  tranquility (ID: 145748)\n",
      "Step 206 ‚Äî Next token: . (ID: 235265)\n",
      "Step 207 ‚Äî Next token: \n",
      " (ID: 108)\n",
      "Step 208 ‚Äî Next token: * (ID: 235287)\n",
      "Step 209 ‚Äî Next token:  ** (ID: 5231)\n",
      "Step 210 ‚Äî Next token: Adventure (ID: 91200)\n",
      "Step 211 ‚Äî Next token:  and (ID: 578)\n",
      "Step 212 ‚Äî Next token:  exploration (ID: 29787)\n",
      "Step 213 ‚Äî Next token: :** (ID: 66058)\n",
      "Step 214 ‚Äî Next token:  The (ID: 714)\n",
      "Step 215 ‚Äî Next token:  dog (ID: 5929)\n",
      "Step 216 ‚Äî Next token: ' (ID: 235303)\n",
      "Step 217 ‚Äî Next token: s (ID: 235256)\n",
      "Step 218 ‚Äî Next token:  exploration (ID: 29787)\n",
      "Step 219 ‚Äî Next token:  of (ID: 576)\n",
      "Step 220 ‚Äî Next token:  the (ID: 573)\n",
      "Step 221 ‚Äî Next token:  snow (ID: 8529)\n",
      "Step 222 ‚Äî Next token: - (ID: 235290)\n",
      "Step 223 ‚Äî Next token: covered (ID: 25044)\n",
      "Step 224 ‚Äî Next token:  landscape (ID: 15487)\n",
      "Step 225 ‚Äî Next token:  suggests (ID: 15904)\n",
      "Step 226 ‚Äî Next token:  an (ID: 671)\n",
      "Step 227 ‚Äî Next token:  adventurous (ID: 92204)\n",
      "Step 228 ‚Äî Next token:  and (ID: 578)\n",
      "Step 229 ‚Äî Next token:  exploratory (ID: 114836)\n",
      "Step 230 ‚Äî Next token:  spirit (ID: 6914)\n",
      "Step 231 ‚Äî Next token: . (ID: 235265)\n",
      "Step 232 ‚Äî Next token:  The (ID: 714)\n",
      "Step 233 ‚Äî Next token:  tracks (ID: 18631)\n",
      "Step 234 ‚Äî Next token:  left (ID: 2731)\n",
      "Step 235 ‚Äî Next token:  behind (ID: 5470)\n",
      "Step 236 ‚Äî Next token:  suggest (ID: 9337)\n",
      "Step 237 ‚Äî Next token:  that (ID: 674)\n",
      "Step 238 ‚Äî Next token:  the (ID: 573)\n",
      "Step 239 ‚Äî Next token:  dog (ID: 5929)\n",
      "Step 240 ‚Äî Next token:  is (ID: 603)\n",
      "Step 241 ‚Äî Next token:  following (ID: 2412)\n",
      "Step 242 ‚Äî Next token:  its (ID: 1277)\n",
      "Step 243 ‚Äî Next token:  own (ID: 1997)\n",
      "Step 244 ‚Äî Next token:  path (ID: 3703)\n",
      "Step 245 ‚Äî Next token:  and (ID: 578)\n",
      "Step 246 ‚Äî Next token:  discovering (ID: 59551)\n",
      "Step 247 ‚Äî Next token:  new (ID: 888)\n",
      "Step 248 ‚Äî Next token:  and (ID: 578)\n",
      "Step 249 ‚Äî Next token:  exciting (ID: 17305)\n",
      "Step 250 ‚Äî Next token:  things (ID: 2652)\n",
      "Step 251 ‚Äî Next token: . (ID: 235265)\n",
      "Step 252 ‚Äî Next token: \n",
      "\n",
      " (ID: 109)\n",
      "Step 253 ‚Äî Next token: ** (ID: 688)\n",
      "Step 254 ‚Äî Next token: Technical (ID: 27423)\n",
      "Step 255 ‚Äî Next token:  Elements (ID: 34762)\n",
      "Step 256 ‚Äî Next token: :** (ID: 66058)\n",
      "Step 257 ‚Äî Next token: \n",
      "\n",
      " (ID: 109)\n",
      "Step 258 ‚Äî Next token: * (ID: 235287)\n",
      "Step 259 ‚Äî Next token:  ** (ID: 5231)\n",
      "Step 260 ‚Äî Next token: Composition (ID: 47286)\n",
      "Step 261 ‚Äî Next token: :** (ID: 66058)\n",
      "Step 262 ‚Äî Next token:  The (ID: 714)\n",
      "Step 263 ‚Äî Next token:  image (ID: 2416)\n",
      "Step 264 ‚Äî Next token:  is (ID: 603)\n",
      "Step 265 ‚Äî Next token:  composed (ID: 18588)\n",
      "Step 266 ‚Äî Next token:  with (ID: 675)\n",
      "Step 267 ‚Äî Next token:  a (ID: 476)\n",
      "Step 268 ‚Äî Next token:  wide (ID: 5396)\n",
      "Step 269 ‚Äî Next token:  angle (ID: 9561)\n",
      "Step 270 ‚Äî Next token:  lens (ID: 18522)\n",
      "Step 271 ‚Äî Next token: , (ID: 235269)\n",
      "Step 272 ‚Äî Next token:  capturing (ID: 62918)\n",
      "Step 273 ‚Äî Next token:  the (ID: 573)\n",
      "Step 274 ‚Äî Next token:  vast (ID: 12380)\n",
      "Step 275 ‚Äî Next token: ness (ID: 1746)\n",
      "Step 276 ‚Äî Next token:  of (ID: 576)\n",
      "Step 277 ‚Äî Next token:  the (ID: 573)\n",
      "Step 278 ‚Äî Next token:  snow (ID: 8529)\n",
      "Step 279 ‚Äî Next token: - (ID: 235290)\n",
      "Step 280 ‚Äî Next token: covered (ID: 25044)\n",
      "Step 281 ‚Äî Next token:  landscape (ID: 15487)\n",
      "Step 282 ‚Äî Next token:  and (ID: 578)\n",
      "Step 283 ‚Äî Next token:  the (ID: 573)\n",
      "Step 284 ‚Äî Next token:  dog (ID: 5929)\n",
      "Step 285 ‚Äî Next token: ' (ID: 235303)\n",
      "Step 286 ‚Äî Next token: s (ID: 235256)\n",
      "Step 287 ‚Äî Next token:  energetic (ID: 53254)\n",
      "Step 288 ‚Äî Next token:  movement (ID: 8069)\n",
      "Step 289 ‚Äî Next token: . (ID: 235265)\n",
      "Step 290 ‚Äî Next token: \n",
      " (ID: 108)\n",
      "Step 291 ‚Äî Next token: * (ID: 235287)\n",
      "Step 292 ‚Äî Next token:  ** (ID: 5231)\n",
      "Step 293 ‚Äî Next token: Lighting (ID: 82295)\n",
      "Step 294 ‚Äî Next token: :** (ID: 66058)\n",
      "Step 295 ‚Äî Next token:  The (ID: 714)\n",
      "Step 296 ‚Äî Next token:  image (ID: 2416)\n",
      "Step 297 ‚Äî Next token:  is (ID: 603)\n",
      "Step 298 ‚Äî Next token:  captured (ID: 23535)\n",
      "Step 299 ‚Äî Next token:  in (ID: 575)\n",
      "Step 300 ‚Äî Next token:  a (ID: 476)\n",
      "Step 301 ‚Äî Next token:  bright (ID: 8660)\n",
      "Step 302 ‚Äî Next token:  and (ID: 578)\n",
      "Step 303 ‚Äî Next token:  crisp (ID: 50102)\n",
      "Step 304 ‚Äî Next token:  light (ID: 2611)\n",
      "Step 305 ‚Äî Next token: , (ID: 235269)\n",
      "Step 306 ‚Äî Next token:  highlighting (ID: 62144)\n",
      "Step 307 ‚Äî Next token:  the (ID: 573)\n",
      "Step 308 ‚Äî Next token:  clean (ID: 3903)\n",
      "Step 309 ‚Äî Next token:  snow (ID: 8529)\n",
      "Step 310 ‚Äî Next token:  and (ID: 578)\n",
      "Step 311 ‚Äî Next token:  the (ID: 573)\n",
      "Step 312 ‚Äî Next token:  dog (ID: 5929)\n",
      "Step 313 ‚Äî Next token: ' (ID: 235303)\n",
      "Step 314 ‚Äî Next token: s (ID: 235256)\n",
      "Step 315 ‚Äî Next token:  bright (ID: 8660)\n",
      "Step 316 ‚Äî Next token:  eyes (ID: 4628)\n",
      "Step 317 ‚Äî Next token: . (ID: 235265)\n",
      "Step 318 ‚Äî Next token: \n",
      " (ID: 108)\n",
      "Step 319 ‚Äî Next token: * (ID: 235287)\n",
      "Step 320 ‚Äî Next token:  ** (ID: 5231)\n",
      "Step 321 ‚Äî Next token: Depth (ID: 25484)\n",
      "Step 322 ‚Äî Next token:  of (ID: 576)\n",
      "Step 323 ‚Äî Next token:  field (ID: 2725)\n",
      "Step 324 ‚Äî Next token: :** (ID: 66058)\n",
      "Step 325 ‚Äî Next token:  The (ID: 714)\n",
      "Step 326 ‚Äî Next token:  image (ID: 2416)\n",
      "Step 327 ‚Äî Next token:  has (ID: 919)\n",
      "Step 328 ‚Äî Next token:  a (ID: 476)\n",
      "Step 329 ‚Äî Next token:  shallow (ID: 27468)\n",
      "Step 330 ‚Äî Next token:  depth (ID: 10624)\n",
      "Step 331 ‚Äî Next token:  of (ID: 576)\n",
      "Step 332 ‚Äî Next token:  field (ID: 2725)\n",
      "Step 333 ‚Äî Next token: , (ID: 235269)\n",
      "Step 334 ‚Äî Next token:  which (ID: 948)\n",
      "Step 335 ‚Äî Next token:  creates (ID: 18460)\n",
      "Step 336 ‚Äî Next token:  a (ID: 476)\n",
      "Step 337 ‚Äî Next token:  sense (ID: 5229)\n",
      "Step 338 ‚Äî Next token:  of (ID: 576)\n",
      "Step 339 ‚Äî Next token:  focus (ID: 6045)\n",
      "Step 340 ‚Äî Next token:  on (ID: 611)\n",
      "Step 341 ‚Äî Next token:  the (ID: 573)\n",
      "Step 342 ‚Äî Next token:  dog (ID: 5929)\n",
      "Step 343 ‚Äî Next token:  and (ID: 578)\n",
      "Step 344 ‚Äî Next token:  the (ID: 573)\n",
      "Step 345 ‚Äî Next token:  tracks (ID: 18631)\n",
      "Step 346 ‚Äî Next token:  in (ID: 575)\n",
      "Step 347 ‚Äî Next token:  the (ID: 573)\n",
      "Step 348 ‚Äî Next token:  snow (ID: 8529)\n",
      "Step 349 ‚Äî Next token: . (ID: 235265)\n",
      "Step 350 ‚Äî Next token: <eos> (ID: 1)\n",
      "<EOS> token reached. Stopping generation.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for step in range(max_new_tokens):\n",
    "    with torch.no_grad():\n",
    "        output = model(input_ids=generated)\n",
    "        next_token_logits = output.logits[:, -1, :]\n",
    "        next_token_id = torch.argmax(next_token_logits, dim=-1, keepdim=True) #dim=-1 ensures the output is a 2D tensor by keeping the last dimension\n",
    "\n",
    "    print(f\"Step {step+1} ‚Äî Next token: {tokenizer.decode(next_token_id[0])} (ID: {next_token_id.item()})\")\n",
    "    generated = torch.cat([generated, next_token_id], dim=-1) # Concatenate (add) the new token to the generated sequence\n",
    "\n",
    "    if next_token_id.item() == tokenizer.eos_token_id:\n",
    "        print(\"<EOS> token reached. Stopping generation.\")\n",
    "        break\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a4208d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìù Final Decoded Text:\n",
      " A dog running through the snow, its paws leaving tracks in the pristine white landscape.\n",
      "\n",
      "**Describe the image in more detail.**\n",
      "\n",
      "**Visual Elements:**\n",
      "\n",
      "* **Snow-covered landscape:** The image captures a winter scene with pristine white snow covering the ground. The snow is clean and pure, creating a stark and beautiful backdrop.\n",
      "* **Dog running through the snow:** The dog is depicted running through the snow, its paws leaving tracks in the pristine white landscape. The movement of the dog is energetic and purposeful, suggesting a sense of adventure and freedom.\n",
      "* **Paw prints:** The dog's paws leaving tracks in the snow create a visual connection between the animal and the environment. They are small and distinct, yet they are enough to convey the movement and energy of the dog.\n",
      "\n",
      "**Emotional Elements:**\n",
      "\n",
      "* **Joy and freedom:** The image conveys a sense of joy and freedom in the winter landscape. The dog's running through the snow is a joyous activity, and the pristine white snow provides a sense of purity and tranquility.\n",
      "* **Adventure and exploration:** The dog's exploration of the snow-covered landscape suggests an adventurous and exploratory spirit. The tracks left behind suggest that the dog is following its own path and discovering new and exciting things.\n",
      "\n",
      "**Technical Elements:**\n",
      "\n",
      "* **Composition:** The image is composed with a wide angle lens, capturing the vastness of the snow-covered landscape and the dog's energetic movement.\n",
      "* **Lighting:** The image is captured in a bright and crisp light, highlighting the clean snow and the dog's bright eyes.\n",
      "* **Depth of field:** The image has a shallow depth of field, which creates a sense of focus on the dog and the tracks in the snow.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "decoded_text = tokenizer.decode(generated[0], skip_special_tokens=True)\n",
    "print(\"\\nüìù Final Decoded Text:\\n\", decoded_text)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gemma-vlm-test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
