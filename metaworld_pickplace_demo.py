#!/usr/bin/env python3
"""
ü§ñ MetaWorld Pick-Place Demo - MuJoCo Native Window ü§ñ

This demo uses MetaWorld v2 with MuJoCo's native window system.
Either MetaWorld works with proper MuJoCo rendering, or we fail gracefully.

Key features:
- ‚úÖ MetaWorld v2 pick-place-v2 environment
- ‚úÖ MuJoCo's native window (not suppressed)
- ‚úÖ TinyVLA model integration if available
- ‚úÖ Proper error handling and graceful failure
- ‚úÖ No simulation fallback - real MetaWorld only

Usage:
    python metaworld_pickplace_demo.py [--episodes N] [--max-steps N]
"""

import argparse
import numpy as np
import time
import sys
import os
from pathlib import Path

# Import MetaWorld - this is required
try:
    import metaworld
    print("‚úÖ MetaWorld imported successfully")
except ImportError as e:
    print(f"‚ùå MetaWorld import failed: {e}")
    print("üí° Please install MetaWorld: pip install git+https://github.com/Farama-Foundation/Metaworld.git")
    sys.exit(1)

# Try to import TinyVLA (optional)
try:
    from tinyvla_loader import load_tinyvla
    HAS_TINYVLA = True
    print("‚úÖ TinyVLA loader available")
except ImportError as e:
    HAS_TINYVLA = False
    print(f"‚ö†Ô∏è TinyVLA not available: {e}")
    print("üé≤ Will use random actions instead")

# Optional PIL for image processing
try:
    from PIL import Image
    HAS_PIL = True
except ImportError:
    HAS_PIL = False
    print("‚ö†Ô∏è PIL not available - visual model features limited")


def load_model_safely():
    """
    ü§ñ Load TinyVLA Model with Comprehensive Error Handling
    
    This function attempts to load the TinyVLA model using multiple fallback strategies:
    1. Try standard model loading
    2. Check multiple checkpoint paths
    3. Handle missing diffusion head gracefully
    4. Return appropriate model or None with descriptive error info
    
    Returns:
        tuple: (model_object_or_None, descriptive_string)
    """
    if not HAS_TINYVLA:
        return None, "TinyVLA loader not available"
    
    print("üîÑ Attempting to load TinyVLA model...")
    
    # Try multiple potential model paths (updated to use latest training checkpoints)
    potential_paths = [
        "VLA_weights/full_training_bs1_final/step_1000",  # Latest completed training
    ]
    
    for model_path in potential_paths:
        if Path(model_path).exists():
            print(f"üîç Trying model path: {model_path}")
            try:
                # Attempt to load TinyVLA model (fix function call with correct parameter)
                model = load_tinyvla(lora_checkpoint_path=model_path)
                if model is not None:
                    print(f"‚úÖ TinyVLA model loaded from: {model_path}")
                    return model, f"TinyVLA (from {model_path})"
                else:
                    print(f"‚ö†Ô∏è Model loading returned None for: {model_path}")
            except Exception as e:
                print(f"‚ö†Ô∏è Model loading failed for {model_path}: {e}")
        else:
            print(f"üîç Path not found: {model_path}")
    
    print("‚ö†Ô∏è No TinyVLA model could be loaded - using random actions")
    return None, "Random Heuristic (TinyVLA unavailable)"


def setup_metaworld_environment():
    """
    üåç Setup MetaWorld Pick-Place-v2 Environment
    
    Creates and configures the MetaWorld environment for pick-place task.
    This should open MuJoCo's native window automatically.
    
    Returns:
        env: MetaWorld environment instance
    """
    print("üåç Setting up MetaWorld pick-place-v2 environment...")
    
    # Set up proper rendering for MuJoCo
    os.environ['MUJOCO_GL'] = 'osmesa'  # Use OSMesa for offscreen rendering
    # Alternatively try: os.environ['MUJOCO_GL'] = 'egl'
    
    # Create MetaWorld ML1 benchmark with pick-place-v2 task
    try:
        ml1 = metaworld.ML1('pick-place-v2', seed=42)
        print(f"‚úÖ MetaWorld ML1 benchmark created")
        
        # Get the environment class and instantiate it
        env_cls = ml1.train_classes['pick-place-v2']
        env = env_cls()  # Create environment without render_mode parameter
        print(f"‚úÖ Environment instantiated: {env_cls}")
        
        # Set the task
        task = list(ml1.train_tasks)[0]  # Get first training task
        env.set_task(task)
        print(f"‚úÖ Task set: {task}")
        
        # Test environment by resetting it (handle tuple return)
        reset_result = env.reset()
        if isinstance(reset_result, tuple):
            initial_obs, info = reset_result
            print(f"‚úÖ Environment reset successful, obs shape: {initial_obs.shape}")
        else:
            initial_obs = reset_result
            print(f"‚úÖ Environment reset successful, obs shape: {initial_obs.shape}")
        
        # Test rendering immediately after setup
        print("üñºÔ∏è Testing rendering after setup...")
        try:
            # Test with MetaWorld v2 correct API
            test_frame = env.render(offscreen=True)
            if test_frame is not None:
                print(f"‚úÖ MetaWorld offscreen rendering test successful: shape {test_frame.shape}")
            else:
                print("‚ö†Ô∏è Offscreen rendering returned None, trying basic render...")
                # Try basic render as fallback
                test_frame = env.render()
                if test_frame is not None:
                    print(f"‚úÖ Basic rendering test successful: shape {getattr(test_frame, 'shape', 'unknown')}")
                else:
                    print("‚ö†Ô∏è All rendering methods failed during setup")
        except Exception as render_test_e:
            print(f"‚ö†Ô∏è Rendering test failed: {render_test_e}")
        
        return env
        
    except Exception as e:
        print(f"‚ùå MetaWorld environment setup failed: {e}")
        print(f"üìã Available environments: {metaworld.ML1.ENV_NAMES if hasattr(metaworld.ML1, 'ENV_NAMES') else 'unknown'}")
        raise


def get_action(model, env, obs, step):
    """
    üéØ Get Action from Model or Heuristic
    
    Args:
        model: TinyVLA model instance (or None)
        env: MetaWorld environment
        obs: Current observation
        step: Current step number
        
    Returns:
        action: Action to take (numpy array)
        action_source: String describing action source
    """
    
    print(f"üîç get_action called: step={step}, model={'available' if model is not None else 'None'}, HAS_PIL={HAS_PIL}")
    
    if model is not None:
        print("üéØ Model is available, trying prediction...")
        try:
            # Get RGB observation for visual model using correct MetaWorld API
            rgb_frame = None
            
            try:
                # Method 1: Use MetaWorld v2 offscreen rendering (correct API)
                rgb_frame = env.render(offscreen=True)
                if rgb_frame is not None:
                    print(f"‚úÖ MetaWorld offscreen render successful: shape {rgb_frame.shape}")
            except Exception as e1:
                print(f"‚ö†Ô∏è Offscreen render failed: {e1}")
                try:
                    # Method 2: Try basic render call as fallback  
                    rgb_frame = env.render()
                    if rgb_frame is not None:
                        print(f"‚úÖ Basic render successful: shape {getattr(rgb_frame, 'shape', 'unknown')}")
                except Exception as e2:
                    print(f"‚ö†Ô∏è Basic render failed: {e2}")
                    
                    # Method 3: Create dummy image if all rendering fails
                    if rgb_frame is None:
                        print(f"‚ö†Ô∏è All rendering methods failed at step {step}")
                        # Use a simple dummy image for testing
                        rgb_frame = np.zeros((224, 224, 3), dtype=np.uint8)
                        print(f"‚úÖ Using dummy image: shape {rgb_frame.shape}")
            
            # If we got a valid image, try model prediction
            if rgb_frame is not None and HAS_PIL:
                print("üñºÔ∏è Processing image for model...")
                try:
                    # Convert to PIL Image for model
                    if isinstance(rgb_frame, np.ndarray) and rgb_frame.size > 0:
                        # Ensure proper image format
                        if rgb_frame.max() <= 1.0:
                            rgb_frame = (rgb_frame * 255).astype(np.uint8)
                        
                        pil_image = Image.fromarray(rgb_frame)
                        print(f"‚úÖ Created PIL image: {pil_image.size} mode={pil_image.mode}")
                        
                        # Get robot state (first 7 elements typically)
                        robot_state = obs[:7] if len(obs) >= 7 else obs
                        print(f"‚úÖ Robot state: shape={robot_state.shape}, values={robot_state[:3]}")
                        
                        # Get model prediction
                        print("üß† Calling model.predict_action...")
                        action = model.predict_action(
                            pil_image, 
                            robot_state, 
                            "pick up the red object and place it on the green target"
                        )
                        
                        # Validate action
                        if not np.isnan(action).any():
                            print(f"‚úÖ Model prediction successful: {action}")
                            return action, "TinyVLA Model"
                        else:
                            print(f"‚ö†Ô∏è Model returned NaN action: {action}")
                            
                except Exception as model_e:
                    print(f"‚ö†Ô∏è Model prediction failed at step {step}: {model_e}")
                    import traceback
                    traceback.print_exc()
            else:
                print(f"‚ö†Ô∏è Cannot proceed: rgb_frame={'valid' if rgb_frame is not None else 'None'}, HAS_PIL={HAS_PIL}")
                    
        except Exception as render_e:
            print(f"‚ö†Ô∏è Rendering setup failed at step {step}: {render_e}")
    else:
        print("‚ö†Ô∏è Model is None, skipping model prediction")
    
    # Fallback to random action
    action = env.action_space.sample()
    if step == 0:  # Only print on first step to avoid spam
        print(f"üé≤ Using random action: {action}")
    return action, "Random"


def run_episode(env, model, episode_num, max_steps):
    """
    üéÆ Run Single Episode
    
    Args:
        env: MetaWorld environment
        model: TinyVLA model (or None)
        episode_num: Episode number for logging
        max_steps: Maximum steps per episode
        
    Returns:
        dict: Episode results
    """
    print(f"\nüé¨ Episode {episode_num} starting...")
    
    # Reset environment (handle tuple return)
    reset_result = env.reset()
    if isinstance(reset_result, tuple):
        obs, info = reset_result
    else:
        obs = reset_result
    
    total_reward = 0
    step = 0
    success = False
    action_sources = []
    
    episode_start_time = time.time()
    
    while step < max_steps:
        # Get action
        action, action_source = get_action(model, env, obs, step)
        action_sources.append(action_source)
        
        # Execute action in environment
        result = env.step(action)
        
        # Handle different return formats (gym compatibility)
        if len(result) == 5:
            obs, reward, terminated, truncated, info = result
            done = terminated or truncated
        else:
            obs, reward, done, info = result
        
        total_reward += reward
        step += 1
        
        # Check for success
        if info.get('success', False):
            success = True
            print(f"üéâ SUCCESS at step {step}! Task completed!")
            break
            
        # Log progress periodically
        if step % 50 == 0:
            print(f"Step {step:3d}: reward={reward:6.3f}, total={total_reward:6.3f}, action_src={action_source}")
        
        if done:
            break
    
    episode_time = time.time() - episode_start_time
    
    # Count action sources
    model_actions = action_sources.count("TinyVLA Model")
    random_actions = action_sources.count("Random")
    
    result = {
        "episode": episode_num,
        "steps": step,
        "total_reward": total_reward,
        "success": success,
        "episode_time": episode_time,
        "model_actions": model_actions,
        "random_actions": random_actions,
        "final_info": dict(info) if info else {}
    }
    
    print(f"üìä Episode {episode_num} results:")
    print(f"   Steps: {step}, Reward: {total_reward:.3f}, Success: {success}")
    print(f"   Time: {episode_time:.1f}s, Model actions: {model_actions}, Random: {random_actions}")
    
    return result


def main():
    """üöÄ Main Demo Function"""
    
    # Parse command line arguments
    parser = argparse.ArgumentParser(description="MetaWorld Pick-Place Demo with MuJoCo Native Window")
    parser.add_argument('--episodes', type=int, default=3, help='Number of episodes to run (default: 3)')
    parser.add_argument('--max-steps', type=int, default=500, help='Maximum steps per episode (default: 500)')
    parser.add_argument('--seed', type=int, default=42, help='Random seed (default: 42)')
    args = parser.parse_args()
    
    print("ü§ñ MetaWorld Pick-Place Demo Starting...")
    print("=" * 60)
    print(f"Episodes: {args.episodes}, Max steps: {args.max_steps}, Seed: {args.seed}")
    print("=" * 60)
    
    # Set random seed
    np.random.seed(args.seed)
    
    try:
        # Load model (optional)
        model, model_info = load_model_safely()
        print(f"ü§ñ Model: {model_info}")
        
        # Setup MetaWorld environment (required)
        env = setup_metaworld_environment()
        print(f"üåç Environment ready: MetaWorld pick-place-v2")
        print(f"üîß Action space: {env.action_space}")
        print(f"üîß Observation space: {env.observation_space}")
        
        # Note about MuJoCo window
        print("\nüñºÔ∏è MuJoCo should open its own rendering window automatically")
        print("   - You can interact with the window (rotate camera, etc.)")
        print("   - Close the window or press Ctrl+C to stop demo")
        
        # Run episodes
        results = []
        total_start_time = time.time()
        
        for episode in range(1, args.episodes + 1):
            try:
                episode_result = run_episode(env, model, episode, args.max_steps)
                results.append(episode_result)
                
                # Brief pause between episodes
                time.sleep(1.0)
                
            except KeyboardInterrupt:
                print("\n‚èπÔ∏è Demo interrupted by user")
                break
            except Exception as e:
                print(f"‚ùå Episode {episode} failed: {e}")
                continue
        
        # Summary
        total_time = time.time() - total_start_time
        
        if results:
            successes = sum(r['success'] for r in results)
            avg_reward = np.mean([r['total_reward'] for r in results])
            avg_steps = np.mean([r['steps'] for r in results])
            total_model_actions = sum(r['model_actions'] for r in results)
            total_random_actions = sum(r['random_actions'] for r in results)
            
            print(f"\nüìä FINAL SUMMARY:")
            print(f"   üéÆ Episodes completed: {len(results)}")
            print(f"   üéØ Success rate: {successes}/{len(results)} ({100*successes/len(results):.1f}%)")
            print(f"   üèÜ Average reward: {avg_reward:.3f}")
            print(f"   üë£ Average steps: {avg_steps:.1f}")
            print(f"   ü§ñ Model actions: {total_model_actions}")
            print(f"   üé≤ Random actions: {total_random_actions}")
            print(f"   ‚è±Ô∏è Total time: {total_time:.1f}s")
            print(f"   üåç Environment: MetaWorld pick-place-v2")
            print(f"   ü§ñ Model: {model_info}")
        
        # Clean up
        if hasattr(env, 'close'):
            env.close()
            
    except KeyboardInterrupt:
        print("\n‚èπÔ∏è Demo stopped by user")
    except Exception as e:
        print(f"\n‚ùå Demo failed: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    
    print("\nüéâ Demo completed!")


if __name__ == "__main__":
    main() 